{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval - DNN Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sparkConfig = {\n",
    "    'spark.executor.memory': '30g',\n",
    "    'spark.driver.memory': '60g',\n",
    "    'spark.master': 'local[*]',\n",
    "    'spark.default.parallelism': '30',\n",
    "    'spark.driver.maxResultSize': '4g',\n",
    "}\n",
    "conf = pyspark.SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('Eval - DNN Evaluations')\n",
    "for k,v in sparkConfig.items():\n",
    "    conf = conf.set(k, v)\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import json, pickle\n",
    "import numpy as N\n",
    "import numpy.random as NR\n",
    "import matplotlib.pyplot as pyplot\n",
    "import seaborn\n",
    "import sklearn.metrics as SkM\n",
    "import pandas as P\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import tqdm\n",
    "import re\n",
    "\n",
    "seaborn.set_style('whitegrid')\n",
    "\n",
    "import keras as K\n",
    "import keras.backend as KB\n",
    "import keras.callbacks as KCb\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.regularizers as KR\n",
    "import keras.optimizers as KO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77176 embedding entries loaded\n"
     ]
    }
   ],
   "source": [
    "import common.data\n",
    "\n",
    "pathChirps = Path('datasets/Chirps')\n",
    "pathStocks = Path('datasets/Stocks')\n",
    "pathAnalyticsChirp = Path('analytics/Chirps')\n",
    "pathModelEmbedding = Path(\"models/embedding/word2vec\")\n",
    "pathStage1 = Path(\"models/stage1\")\n",
    "\n",
    "startTrain = datetime.date(2017, 1, 1)\n",
    "endTrain = datetime.date(2019, 1, 1)\n",
    "startTest = endTrain\n",
    "endTest = datetime.date(2019, 7, 1)\n",
    "\n",
    "pathTestInstances = pathStage1 / 'instances_test'\n",
    "\n",
    "with open(pathStage1 / 'properties.json', 'r') as f:\n",
    "    sampleProperties = json.load(f)\n",
    "    \n",
    "# Word2Vec\n",
    "\n",
    "with open(pathModelEmbedding / 'properties.json', 'r') as f:\n",
    "    embeddingProperties = json.load(f)\n",
    "with open(pathModelEmbedding / 'dict.pickle', 'rb') as f:\n",
    "    word2vec = pickle.load(f)\n",
    "print(f\"{len(word2vec)} embedding entries loaded\")\n",
    "\n",
    "# Stock data\n",
    "\n",
    "ticker = \"^DJI\"\n",
    "stockDf = P.read_csv(pathStocks / f'{ticker}.csv').set_index('Date')\n",
    "stockDf.index = stockDf.index.map(datetime.datetime.fromisoformat).map(lambda x:x.date())\n",
    "stockDf_train = stockDf[stockDf.index.map(lambda x:startTrain <= x and x < endTrain)]\n",
    "stockDf_test = stockDf[stockDf.index.map(lambda x:startTest <= x and x < endTest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2019, 5, 8),\n",
       "  array(['reuters journalists free in myanmar', 'separate kids to parents',\n",
       "         'news tell a story', ..., 'barr to look into the material g',\n",
       "         'start from the ground with dirt', 'the family get a settlement'],\n",
       "        dtype='<U129')),\n",
       " (datetime.date(2019, 1, 22),\n",
       "  array(['bet he\\'ll be heading to the caribbean soon... gofundme \"trump wall\" donors have give million',\n",
       "         'to pull e-cigarettes off the market', 'rig polls for trump', ...,\n",
       "         'the moment mr dunkerton financially supported people',\n",
       "         'a court have order four', 'trump laud football players'],\n",
       "        dtype='<U114'))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_sample_transform = common.data.get_data_to_sample_transform(word2vec, embeddingProperties, stockDf['Y'], sc=sc)\n",
    "\n",
    "rddTest = sc.pickleFile(str(pathTestInstances), 32) \\\n",
    "    .cache()\n",
    "rddTest.takeSample(False, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[1] at objectFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples = rddTest.collect()\n",
    "rddTest.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf_strategy = tf.distribute.MirroredStrategy()\n",
    "def sign_accuracy(y_true, y_pred):\n",
    "    return KB.mean((y_true * y_pred) >= 0)\n",
    "custom_objects = {'sign_accuracy': sign_accuracy}\n",
    "with tf_strategy.scope():\n",
    "    model_cnn = KM.load_model(f'models/nn-conv-{ticker}/e10', custom_objects=custom_objects)\n",
    "    model_cnnatt = KM.load_model(f'models/nn-convatt-{ticker}/e10', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/496 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib64/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [15:04<00:00,  1.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>-0.487070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>-0.621753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>-0.095621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>-0.305309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>-0.114439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>-1.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>-0.252180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>-1.429891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>-0.145209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.296895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      Yhat\n",
       "0   2019-02-13 -0.487070\n",
       "1   2019-02-13 -0.621753\n",
       "2   2019-02-13 -0.095621\n",
       "3   2019-02-13 -0.305309\n",
       "4   2019-02-13 -0.114439\n",
       "..         ...       ...\n",
       "3   2019-06-21 -1.003469\n",
       "4   2019-06-21 -0.252180\n",
       "5   2019-06-21 -1.429891\n",
       "6   2019-06-21 -0.145209\n",
       "7   2019-06-21  0.296895\n",
       "\n",
       "[3968 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_evaluate(model):\n",
    "    # Read test samples in batches\n",
    "    batch_size = 8\n",
    "    n_batches = int(N.ceil(len(test_samples) / batch_size))\n",
    "    df = P.DataFrame()\n",
    "    for i in tqdm.tqdm(range(n_batches)):\n",
    "        batch = test_samples[i*batch_size:(i+1)*batch_size]\n",
    "        batch_embed = N.array([data_to_sample_transform(x)[0] for x in batch])\n",
    "        \n",
    "        y = model.predict(batch_embed)[...,0]\n",
    "        \n",
    "        batch_result = {\n",
    "            'date': [d for d,_ in batch],\n",
    "            'Yhat': y,\n",
    "        }\n",
    "        \n",
    "        df = P.concat([df, P.DataFrame(batch_result)], axis=0)\n",
    "    return df\n",
    "\n",
    "df_cnn = model_evaluate(model_cnn)\n",
    "df_cnn.to_csv(f'analytics/cnn_{ticker}_raw.csv', index=False)\n",
    "df_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [14:58<00:00,  1.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>0.320398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>0.205320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>-0.329300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>0.312234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>-0.313654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.155694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>-0.199397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.169672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.113658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>0.099363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      Yhat\n",
       "0   2019-02-13  0.320398\n",
       "1   2019-02-13  0.205320\n",
       "2   2019-02-13 -0.329300\n",
       "3   2019-02-13  0.312234\n",
       "4   2019-02-13 -0.313654\n",
       "..         ...       ...\n",
       "3   2019-06-21  0.155694\n",
       "4   2019-06-21 -0.199397\n",
       "5   2019-06-21  0.169672\n",
       "6   2019-06-21  0.113658\n",
       "7   2019-06-21  0.099363\n",
       "\n",
       "[3968 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_cnnatt = model_evaluate(model_cnnatt)\n",
    "df_cnnatt.to_csv(f'analytics/cnnatt_{ticker}_raw.csv', index=False)\n",
    "df_cnnatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
