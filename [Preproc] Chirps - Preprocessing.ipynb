{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chirps Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sparkConfig = {\n",
    "    'spark.executor.memory': '60g',\n",
    "    'spark.driver.memory': '30g',\n",
    "    'spark.master': 'local[*]',\n",
    "    'spark.default.parallelism': '30',\n",
    "}\n",
    "sc = pyspark.SparkContext('local[*]', 'Chirp Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import numpy as N\n",
    "import numpy.random as NR\n",
    "import matplotlib.pyplot as pyplot\n",
    "import seaborn\n",
    "import pandas as P\n",
    "from pathlib import Path\n",
    "import pyspark.mllib as M\n",
    "\n",
    "seaborn.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.twitter\n",
    "basepath = Path('datasets/Chirps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Time range filter\n",
    "\n",
    "From Exploration 1, most of the tweets occur between 2017/01/01 and 2019/07/01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTrain = datetime.datetime(2017, 1, 1)\n",
    "endTrain = datetime.datetime(2019, 1, 1)\n",
    "startTest = endTrain\n",
    "endTest = datetime.datetime(2019, 7, 1)\n",
    "\n",
    "pathTrainInstances = basepath / 'instances_train.tsv'\n",
    "pathTestInstances = basepath / 'instances_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readline(l):\n",
    "    i1, i2 = common.twitter.chirps_instance_readline(l)\n",
    "    try:\n",
    "        # This would fail on 4 samples because of mismatched }'s.\n",
    "        # Remove these samples now rather than later\n",
    "        li1 = i1.tokenised_substitute_string\n",
    "        li2 = i2.tokenised_substitute_string\n",
    "        return [i1, i2]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "def instances_filter(startTime, endTime, filename, collect=False):\n",
    "    def time_range_filter(x):\n",
    "        return startTime <= x.datetime and x.datetime < endTime\n",
    "    def to_tweet_id(x):\n",
    "        # Filter by distinct tweet id's\n",
    "        return (x.tweetId, x)\n",
    "\n",
    "    rdd = sc.textFile(str(basepath / 'instances.tsv'), 90) \\\n",
    "        .flatMap(readline) \\\n",
    "        .filter(time_range_filter) \\\n",
    "        .map(to_tweet_id) \\\n",
    "        .reduceByKey(lambda a,b: a, 90) \\\n",
    "        .values() \\\n",
    "        .sortBy(lambda x:x.timestamp) \\\n",
    "        .map(lambda x:x.serialise)\n",
    "    print(f\"{rdd.count()} samples read\")\n",
    "    if collect:\n",
    "        with open(filename, 'w') as f:\n",
    "            for x in rdd.collect():\n",
    "                f.write(\"%s\\n\" % x)\n",
    "    else:\n",
    "        rdd.saveAsTextFile(str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6809312 samples read\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "if not pathTrainInstances.exists():\n",
    "    instances_filter(startTrain, endTrain, pathTrainInstances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950076 samples read\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "if not pathTestInstances.exists():\n",
    "    instances_filter(startTest, endTest, pathTestInstances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
