{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Stage2 Type1 - CNN based\n",
    "\n",
    "This model uses Stage 1 - Word Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sparkConfig = {\n",
    "    'spark.executor.memory': '30g',\n",
    "    'spark.driver.memory': '60g',\n",
    "    'spark.master': 'local[*]',\n",
    "    'spark.default.parallelism': '30',\n",
    "    'spark.driver.maxResultSize': '4g',\n",
    "}\n",
    "conf = pyspark.SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('Model - Stage2 Type1 - CNN based')\n",
    "for k,v in sparkConfig.items():\n",
    "    conf = conf.set(k, v)\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "nWorkers = 0 # Set this number to the number of GPU machines on your cluster. If 0 it forces single machine training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import json, pickle\n",
    "import numpy as N\n",
    "import numpy.random as NR\n",
    "import matplotlib.pyplot as pyplot\n",
    "import seaborn\n",
    "import pandas as P\n",
    "from pathlib import Path\n",
    "import pyspark.mllib as SM\n",
    "import pyspark.mllib.feature as SMF\n",
    "\n",
    "seaborn.set_style('whitegrid')\n",
    "\n",
    "import keras as K\n",
    "import keras.backend as KB\n",
    "import keras.callbacks as KCb\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.regularizers as KR\n",
    "import keras.optimizers as KO\n",
    "import elephas as E\n",
    "import elephas.spark_model as ESm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'common.data' from '/data/common/data.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import common.data\n",
    "importlib.reload(common.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathChirps = Path('datasets/Chirps')\n",
    "pathStocks = Path('datasets/Stocks')\n",
    "pathAnalyticsChirp = Path('analytics/Chirps')\n",
    "pathModelEmbedding = Path(\"models/embedding/word2vec\")\n",
    "pathStage1 = Path(\"models/stage1\")\n",
    "\n",
    "startTrain = datetime.date(2017, 1, 1)\n",
    "endTrain = datetime.date(2019, 1, 1)\n",
    "startTest = endTrain\n",
    "endTest = datetime.date(2019, 7, 1)\n",
    "\n",
    "pathTrainInstances = pathStage1 / 'instances_train'\n",
    "pathTestInstances = pathStage1 / 'instances_test'\n",
    "\n",
    "with open(pathStage1 / 'properties.json', 'r') as f:\n",
    "    sampleProperties = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77176 embedding entries loaded\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec\n",
    "\n",
    "with open(pathModelEmbedding / 'properties.json', 'r') as f:\n",
    "    embeddingProperties = json.load(f)\n",
    "with open(pathModelEmbedding / 'dict.pickle', 'rb') as f:\n",
    "    word2vec = pickle.load(f)\n",
    "print(f\"{len(word2vec)} embedding entries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>S</th>\n",
       "      <th>X</th>\n",
       "      <th>sigma_hat</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>19872.859375</td>\n",
       "      <td>19938.529297</td>\n",
       "      <td>19775.929688</td>\n",
       "      <td>19881.759766</td>\n",
       "      <td>339180000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19877.309570</td>\n",
       "      <td>19875.675886</td>\n",
       "      <td>57.021305</td>\n",
       "      <td>0.673759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>19890.939453</td>\n",
       "      <td>19956.140625</td>\n",
       "      <td>19878.830078</td>\n",
       "      <td>19942.160156</td>\n",
       "      <td>280010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19916.549805</td>\n",
       "      <td>19914.094491</td>\n",
       "      <td>62.168018</td>\n",
       "      <td>-0.087547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>19924.560547</td>\n",
       "      <td>19948.599609</td>\n",
       "      <td>19811.119141</td>\n",
       "      <td>19899.289062</td>\n",
       "      <td>269920000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19911.924805</td>\n",
       "      <td>19908.651881</td>\n",
       "      <td>58.908224</td>\n",
       "      <td>0.384209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>19906.960938</td>\n",
       "      <td>19999.630859</td>\n",
       "      <td>19834.080078</td>\n",
       "      <td>19963.800781</td>\n",
       "      <td>277700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19935.380859</td>\n",
       "      <td>19931.284969</td>\n",
       "      <td>73.430061</td>\n",
       "      <td>-0.387225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>19931.410156</td>\n",
       "      <td>19943.779297</td>\n",
       "      <td>19887.380859</td>\n",
       "      <td>19887.380859</td>\n",
       "      <td>287510000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19909.395508</td>\n",
       "      <td>19902.851029</td>\n",
       "      <td>54.289081</td>\n",
       "      <td>-0.815226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>22317.279297</td>\n",
       "      <td>22339.869141</td>\n",
       "      <td>21792.199219</td>\n",
       "      <td>21792.199219</td>\n",
       "      <td>308420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22054.739258</td>\n",
       "      <td>21409.960941</td>\n",
       "      <td>1493.130066</td>\n",
       "      <td>0.202531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>21857.730469</td>\n",
       "      <td>22878.919922</td>\n",
       "      <td>21712.529297</td>\n",
       "      <td>22878.449219</td>\n",
       "      <td>433080000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22368.089844</td>\n",
       "      <td>21712.365957</td>\n",
       "      <td>959.602075</td>\n",
       "      <td>0.520857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>22629.060547</td>\n",
       "      <td>23138.890625</td>\n",
       "      <td>22267.419922</td>\n",
       "      <td>23138.820312</td>\n",
       "      <td>407940000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22883.940430</td>\n",
       "      <td>22212.181458</td>\n",
       "      <td>579.844457</td>\n",
       "      <td>0.423706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>23213.609375</td>\n",
       "      <td>23381.880859</td>\n",
       "      <td>22981.330078</td>\n",
       "      <td>23062.400391</td>\n",
       "      <td>336510000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23138.004883</td>\n",
       "      <td>22457.864894</td>\n",
       "      <td>587.052455</td>\n",
       "      <td>0.165055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>23153.939453</td>\n",
       "      <td>23333.179688</td>\n",
       "      <td>23118.300781</td>\n",
       "      <td>23327.460938</td>\n",
       "      <td>288830000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23240.700195</td>\n",
       "      <td>22554.760590</td>\n",
       "      <td>644.131836</td>\n",
       "      <td>-0.060541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close     Volume  \\\n",
       "Date                                                                            \n",
       "2017-01-03  19872.859375  19938.529297  19775.929688  19881.759766  339180000   \n",
       "2017-01-04  19890.939453  19956.140625  19878.830078  19942.160156  280010000   \n",
       "2017-01-05  19924.560547  19948.599609  19811.119141  19899.289062  269920000   \n",
       "2017-01-06  19906.960938  19999.630859  19834.080078  19963.800781  277700000   \n",
       "2017-01-09  19931.410156  19943.779297  19887.380859  19887.380859  287510000   \n",
       "...                  ...           ...           ...           ...        ...   \n",
       "2018-12-24  22317.279297  22339.869141  21792.199219  21792.199219  308420000   \n",
       "2018-12-26  21857.730469  22878.919922  21712.529297  22878.449219  433080000   \n",
       "2018-12-27  22629.060547  23138.890625  22267.419922  23138.820312  407940000   \n",
       "2018-12-28  23213.609375  23381.880859  22981.330078  23062.400391  336510000   \n",
       "2018-12-31  23153.939453  23333.179688  23118.300781  23327.460938  288830000   \n",
       "\n",
       "            Dividends  Stock Splits             S             X    sigma_hat  \\\n",
       "Date                                                                           \n",
       "2017-01-03          0             0  19877.309570  19875.675886    57.021305   \n",
       "2017-01-04          0             0  19916.549805  19914.094491    62.168018   \n",
       "2017-01-05          0             0  19911.924805  19908.651881    58.908224   \n",
       "2017-01-06          0             0  19935.380859  19931.284969    73.430061   \n",
       "2017-01-09          0             0  19909.395508  19902.851029    54.289081   \n",
       "...               ...           ...           ...           ...          ...   \n",
       "2018-12-24          0             0  22054.739258  21409.960941  1493.130066   \n",
       "2018-12-26          0             0  22368.089844  21712.365957   959.602075   \n",
       "2018-12-27          0             0  22883.940430  22212.181458   579.844457   \n",
       "2018-12-28          0             0  23138.004883  22457.864894   587.052455   \n",
       "2018-12-31          0             0  23240.700195  22554.760590   644.131836   \n",
       "\n",
       "                   Y  \n",
       "Date                  \n",
       "2017-01-03  0.673759  \n",
       "2017-01-04 -0.087547  \n",
       "2017-01-05  0.384209  \n",
       "2017-01-06 -0.387225  \n",
       "2017-01-09 -0.815226  \n",
       "...              ...  \n",
       "2018-12-24  0.202531  \n",
       "2018-12-26  0.520857  \n",
       "2018-12-27  0.423706  \n",
       "2018-12-28  0.165055  \n",
       "2018-12-31 -0.060541  \n",
       "\n",
       "[502 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stock data\n",
    "\n",
    "ticker = \"^DJI\"\n",
    "stockDf = P.read_csv(pathStocks / f'{ticker}.csv').set_index('Date')\n",
    "stockDf.index = stockDf.index.map(datetime.datetime.fromisoformat).map(lambda x:x.date())\n",
    "stockDf_train = stockDf[stockDf.index.map(lambda x:startTrain <= x and x < endTrain)]\n",
    "stockDf_test = stockDf[stockDf.index.map(lambda x:startTest <= x and x < endTest)]\n",
    "stockDf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2018, 4, 24),\n",
       "  array(['people to search over 100,000 volumes',\n",
       "         'trump reject new sanctions', 'flynn interrupt trump', ...,\n",
       "         'trump will not invite democrats',\n",
       "         'chemical weapons inspectors collect samples',\n",
       "         'scandal spark change'], dtype='<U112')),\n",
       " (datetime.date(2018, 9, 10),\n",
       "  array(['hollywood grande dame carole cook go after trump',\n",
       "         'obama ask students', 'run for office on both sides', ...,\n",
       "         'stick eyes on fish', 'teen get death', 'addis ababa the city'],\n",
       "        dtype='<U114'))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_sample_transform = common.data.get_data_to_sample_transform(word2vec, embeddingProperties, stockDf['Y'], sc=sc)\n",
    "\n",
    "rddTrain = sc.pickleFile(str(pathTrainInstances), 32) \\\n",
    "    .cache()\n",
    "rddTrain.takeSample(False, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathModel = Path(f'models/nn-conv-{ticker}')\n",
    "pathModel.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Stage2Type1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 2048, 26, 128)]   0         \n",
      "_________________________________________________________________\n",
      "td_Conv1 (TimeDistributed)   (None, 2048, 26, 64)      32832     \n",
      "_________________________________________________________________\n",
      "Conv1A (LeakyReLU)           (None, 2048, 26, 64)      0         \n",
      "_________________________________________________________________\n",
      "td_Pool1 (TimeDistributed)   (None, 2048, 13, 64)      0         \n",
      "_________________________________________________________________\n",
      "td_Conv2 (TimeDistributed)   (None, 2048, 13, 64)      16448     \n",
      "_________________________________________________________________\n",
      "Conv2A (LeakyReLU)           (None, 2048, 13, 64)      0         \n",
      "_________________________________________________________________\n",
      "td_Pool2 (TimeDistributed)   (None, 2048, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "td_Conv3 (TimeDistributed)   (None, 2048, 6, 1)        257       \n",
      "_________________________________________________________________\n",
      "Conv3A (LeakyReLU)           (None, 2048, 6, 1)        0         \n",
      "_________________________________________________________________\n",
      "td_Flatten (TimeDistributed) (None, 2048, 6)           0         \n",
      "_________________________________________________________________\n",
      "GlobalPool1 (GlobalMaxPoolin (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 32)                224       \n",
      "_________________________________________________________________\n",
      "Dense1A (LeakyReLU)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "DenseO (Dense)               (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 49,794\n",
      "Trainable params: 49,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def time_dist(l):\n",
    "    return KL.TimeDistributed(l, name='td_' + l.name)\n",
    "def create_model(name=\"Stage2Type1\"):\n",
    "    \n",
    "    def get_act(n):\n",
    "        return KL.LeakyReLU(0.01, name=n)\n",
    "    def get_kernel_reg():\n",
    "        return KR.l2(1e-4)\n",
    "    lIn = KL.Input((sampleProperties['sampleSize'], embeddingProperties['tweet_len'], embeddingProperties['embedding_size']), name=\"Input\")\n",
    "    layers = [\n",
    "        # \n",
    "        time_dist(KL.Conv1D(64, 4, 1, kernel_regularizer=get_kernel_reg(), padding='same', name='Conv1')),\n",
    "        get_act('Conv1A'),\n",
    "        time_dist(KL.MaxPooling1D(2, name='Pool1')),\n",
    "        time_dist(KL.Conv1D(64, 4, 1, kernel_regularizer=get_kernel_reg(), padding='same', name='Conv2')),\n",
    "        get_act('Conv2A'),\n",
    "        time_dist(KL.MaxPooling1D(2, name='Pool2')),\n",
    "        time_dist(KL.Conv1D(1, 4, 1, kernel_regularizer=get_kernel_reg(), padding='same', name='Conv3')),\n",
    "        get_act('Conv3A'),\n",
    "        time_dist(KL.Flatten(name=\"Flatten\")),\n",
    "        KL.GlobalMaxPooling1D(name=\"GlobalPool1\"),\n",
    "        KL.Dense(32, kernel_regularizer=get_kernel_reg(), name=\"Dense1\"),\n",
    "        get_act('Dense1A'),\n",
    "        KL.Dense(1, kernel_regularizer=get_kernel_reg(), activation=None, name=\"DenseO\"),\n",
    "    ]\n",
    "    out = lIn\n",
    "    for l in layers:\n",
    "        out = l(out)\n",
    "        \n",
    "    return KM.Model(inputs=lIn, outputs=out, name=name)\n",
    "\n",
    "if nWorkers > 0:\n",
    "    model = create_model()\n",
    "else:\n",
    "    with tf_strategy.scope():\n",
    "        model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_accuracy(y_true, y_pred):\n",
    "    return KB.mean((y_true * y_pred) >= 0)\n",
    "model.compile(loss='mse', metrics=['mse', sign_accuracy], optimizer='adam')\n",
    "callback_checkpoint = KCb.ModelCheckpoint(str(pathModel / 'e{epoch:02d}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.6166 - mse: 0.6000 - sign_accuracy: 0.6084INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e02/assets\n",
      "512/512 [==============================] - 2316s 5s/step - loss: 0.6166 - mse: 0.6000 - sign_accuracy: 0.6084\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.5730 - mse: 0.5546 - sign_accuracy: 0.6472INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e03/assets\n",
      "512/512 [==============================] - 2303s 4s/step - loss: 0.5730 - mse: 0.5546 - sign_accuracy: 0.6472\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.5658 - mse: 0.5456 - sign_accuracy: 0.6846INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e04/assets\n",
      "512/512 [==============================] - 2301s 4s/step - loss: 0.5658 - mse: 0.5456 - sign_accuracy: 0.6846\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4972 - mse: 0.4749 - sign_accuracy: 0.6942INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e05/assets\n",
      "512/512 [==============================] - 2304s 5s/step - loss: 0.4972 - mse: 0.4749 - sign_accuracy: 0.6942\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4687 - mse: 0.4448 - sign_accuracy: 0.7047INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e06/assets\n",
      "512/512 [==============================] - 2303s 4s/step - loss: 0.4687 - mse: 0.4448 - sign_accuracy: 0.7047\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4805 - mse: 0.4549 - sign_accuracy: 0.7107INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e07/assets\n",
      "512/512 [==============================] - 2310s 5s/step - loss: 0.4805 - mse: 0.4549 - sign_accuracy: 0.7107\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4711 - mse: 0.4438 - sign_accuracy: 0.7157INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e08/assets\n",
      "512/512 [==============================] - 2313s 5s/step - loss: 0.4711 - mse: 0.4438 - sign_accuracy: 0.7157\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4664 - mse: 0.4375 - sign_accuracy: 0.7102INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e09/assets\n",
      "512/512 [==============================] - 2314s 5s/step - loss: 0.4664 - mse: 0.4375 - sign_accuracy: 0.7102\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4356 - mse: 0.4051 - sign_accuracy: 0.7205INFO:tensorflow:Assets written to: models/nn-conv-^DJI/e10/assets\n",
      "512/512 [==============================] - 2317s 5s/step - loss: 0.4356 - mse: 0.4051 - sign_accuracy: 0.7205\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "if nWorkers > 0:\n",
    "    sparkModel = ESm.SparkModel(model, frequency='epoch', mode='asynchronous')\n",
    "    sparkModel.master_optimizer = KO.Adam()\n",
    "    hist = sparkModel.fit(rddTrain.repartition(nWorkers), epochs=nEpochs, batch_size=32, verbose=1)\n",
    "else:\n",
    "    batch_size = 16\n",
    "    repeat_batch = 4\n",
    "    def sample_generator():\n",
    "        while True:\n",
    "            x = rddTrain.takeSample(False, batch_size*repeat_batch)\n",
    "            x = [data_to_sample_transform(s) for s in x]\n",
    "            x, y = zip(*x)\n",
    "            x = N.array(x)\n",
    "            y = N.array(y)\n",
    "            for i in range(repeat_batch):\n",
    "                slic = slice(i*batch_size, (i+1)*batch_size)\n",
    "                yield x[slic], y[slic]\n",
    "    hist = model.fit(x=sample_generator(), epochs=nEpochs,  steps_per_epoch=512, callbacks=[callback_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(pathModel / 'e10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KM.load_model(pathModel / 'e01', custom_objects={'sign_accuracy': sign_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pathModel / 'hist.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'params': hist.params,\n",
    "        'history': hist.history,\n",
    "        'epoch': hist.epoch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
