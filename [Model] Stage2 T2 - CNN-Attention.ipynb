{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Stage2 Type2 - CNN-Attention\n",
    "\n",
    "This model uses Stage 1 - Word Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sparkConfig = {\n",
    "    'spark.executor.memory': '30g',\n",
    "    'spark.driver.memory': '60g',\n",
    "    'spark.master': 'local[*]',\n",
    "    'spark.default.parallelism': '30',\n",
    "    'spark.driver.maxResultSize': '4g',\n",
    "}\n",
    "conf = pyspark.SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('Model - Stage2 Type2 - CNN-Attention based')\n",
    "for k,v in sparkConfig.items():\n",
    "    conf = conf.set(k, v)\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "nWorkers = 0 # Set this number to the number of GPU machines on your cluster. If 0 it forces single machine training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import json, pickle\n",
    "import numpy as N\n",
    "import numpy.random as NR\n",
    "import matplotlib.pyplot as pyplot\n",
    "import seaborn\n",
    "import pandas as P\n",
    "from pathlib import Path\n",
    "import pyspark.mllib as SM\n",
    "import pyspark.mllib.feature as SMF\n",
    "import os\n",
    "\n",
    "seaborn.set_style('whitegrid')\n",
    "\n",
    "import keras as K\n",
    "import keras.backend as KB\n",
    "import keras.callbacks as KCb\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.regularizers as KR\n",
    "import keras.optimizers as KO\n",
    "import elephas as E\n",
    "import elephas.spark_model as ESm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'common.data' from '/data/common/data.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import common.data\n",
    "importlib.reload(common.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathChirps = Path('datasets/Chirps')\n",
    "pathStocks = Path('datasets/Stocks')\n",
    "pathAnalyticsChirp = Path('analytics/Chirps')\n",
    "pathModelEmbedding = Path(\"models/embedding/word2vec\")\n",
    "pathStage1 = Path(\"models/stage1\")\n",
    "\n",
    "startTrain = datetime.date(2017, 1, 1)\n",
    "endTrain = datetime.date(2019, 1, 1)\n",
    "startTest = endTrain\n",
    "endTest = datetime.date(2019, 7, 1)\n",
    "\n",
    "pathTrainInstances = pathStage1 / 'instances_train'\n",
    "pathTestInstances = pathStage1 / 'instances_test'\n",
    "\n",
    "with open(pathStage1 / 'properties.json', 'r') as f:\n",
    "    sampleProperties = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77176 embedding entries loaded\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec\n",
    "\n",
    "with open(pathModelEmbedding / 'properties.json', 'r') as f:\n",
    "    embeddingProperties = json.load(f)\n",
    "with open(pathModelEmbedding / 'dict.pickle', 'rb') as f:\n",
    "    word2vec = pickle.load(f)\n",
    "print(f\"{len(word2vec)} embedding entries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>S</th>\n",
       "      <th>X</th>\n",
       "      <th>sigma_hat</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>19872.859375</td>\n",
       "      <td>19938.529297</td>\n",
       "      <td>19775.929688</td>\n",
       "      <td>19881.759766</td>\n",
       "      <td>339180000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19877.309570</td>\n",
       "      <td>19875.675886</td>\n",
       "      <td>57.021305</td>\n",
       "      <td>0.673759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>19890.939453</td>\n",
       "      <td>19956.140625</td>\n",
       "      <td>19878.830078</td>\n",
       "      <td>19942.160156</td>\n",
       "      <td>280010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19916.549805</td>\n",
       "      <td>19914.094491</td>\n",
       "      <td>62.168018</td>\n",
       "      <td>-0.087547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>19924.560547</td>\n",
       "      <td>19948.599609</td>\n",
       "      <td>19811.119141</td>\n",
       "      <td>19899.289062</td>\n",
       "      <td>269920000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19911.924805</td>\n",
       "      <td>19908.651881</td>\n",
       "      <td>58.908224</td>\n",
       "      <td>0.384209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>19906.960938</td>\n",
       "      <td>19999.630859</td>\n",
       "      <td>19834.080078</td>\n",
       "      <td>19963.800781</td>\n",
       "      <td>277700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19935.380859</td>\n",
       "      <td>19931.284969</td>\n",
       "      <td>73.430061</td>\n",
       "      <td>-0.387225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>19931.410156</td>\n",
       "      <td>19943.779297</td>\n",
       "      <td>19887.380859</td>\n",
       "      <td>19887.380859</td>\n",
       "      <td>287510000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19909.395508</td>\n",
       "      <td>19902.851029</td>\n",
       "      <td>54.289081</td>\n",
       "      <td>-0.815226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>22317.279297</td>\n",
       "      <td>22339.869141</td>\n",
       "      <td>21792.199219</td>\n",
       "      <td>21792.199219</td>\n",
       "      <td>308420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22054.739258</td>\n",
       "      <td>21409.960941</td>\n",
       "      <td>1493.130066</td>\n",
       "      <td>0.202531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>21857.730469</td>\n",
       "      <td>22878.919922</td>\n",
       "      <td>21712.529297</td>\n",
       "      <td>22878.449219</td>\n",
       "      <td>433080000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22368.089844</td>\n",
       "      <td>21712.365957</td>\n",
       "      <td>959.602075</td>\n",
       "      <td>0.520857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>22629.060547</td>\n",
       "      <td>23138.890625</td>\n",
       "      <td>22267.419922</td>\n",
       "      <td>23138.820312</td>\n",
       "      <td>407940000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22883.940430</td>\n",
       "      <td>22212.181458</td>\n",
       "      <td>579.844457</td>\n",
       "      <td>0.423706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>23213.609375</td>\n",
       "      <td>23381.880859</td>\n",
       "      <td>22981.330078</td>\n",
       "      <td>23062.400391</td>\n",
       "      <td>336510000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23138.004883</td>\n",
       "      <td>22457.864894</td>\n",
       "      <td>587.052455</td>\n",
       "      <td>0.165055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>23153.939453</td>\n",
       "      <td>23333.179688</td>\n",
       "      <td>23118.300781</td>\n",
       "      <td>23327.460938</td>\n",
       "      <td>288830000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23240.700195</td>\n",
       "      <td>22554.760590</td>\n",
       "      <td>644.131836</td>\n",
       "      <td>-0.060541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Open          High           Low         Close     Volume  \\\n",
       "Date                                                                            \n",
       "2017-01-03  19872.859375  19938.529297  19775.929688  19881.759766  339180000   \n",
       "2017-01-04  19890.939453  19956.140625  19878.830078  19942.160156  280010000   \n",
       "2017-01-05  19924.560547  19948.599609  19811.119141  19899.289062  269920000   \n",
       "2017-01-06  19906.960938  19999.630859  19834.080078  19963.800781  277700000   \n",
       "2017-01-09  19931.410156  19943.779297  19887.380859  19887.380859  287510000   \n",
       "...                  ...           ...           ...           ...        ...   \n",
       "2018-12-24  22317.279297  22339.869141  21792.199219  21792.199219  308420000   \n",
       "2018-12-26  21857.730469  22878.919922  21712.529297  22878.449219  433080000   \n",
       "2018-12-27  22629.060547  23138.890625  22267.419922  23138.820312  407940000   \n",
       "2018-12-28  23213.609375  23381.880859  22981.330078  23062.400391  336510000   \n",
       "2018-12-31  23153.939453  23333.179688  23118.300781  23327.460938  288830000   \n",
       "\n",
       "            Dividends  Stock Splits             S             X    sigma_hat  \\\n",
       "Date                                                                           \n",
       "2017-01-03          0             0  19877.309570  19875.675886    57.021305   \n",
       "2017-01-04          0             0  19916.549805  19914.094491    62.168018   \n",
       "2017-01-05          0             0  19911.924805  19908.651881    58.908224   \n",
       "2017-01-06          0             0  19935.380859  19931.284969    73.430061   \n",
       "2017-01-09          0             0  19909.395508  19902.851029    54.289081   \n",
       "...               ...           ...           ...           ...          ...   \n",
       "2018-12-24          0             0  22054.739258  21409.960941  1493.130066   \n",
       "2018-12-26          0             0  22368.089844  21712.365957   959.602075   \n",
       "2018-12-27          0             0  22883.940430  22212.181458   579.844457   \n",
       "2018-12-28          0             0  23138.004883  22457.864894   587.052455   \n",
       "2018-12-31          0             0  23240.700195  22554.760590   644.131836   \n",
       "\n",
       "                   Y  \n",
       "Date                  \n",
       "2017-01-03  0.673759  \n",
       "2017-01-04 -0.087547  \n",
       "2017-01-05  0.384209  \n",
       "2017-01-06 -0.387225  \n",
       "2017-01-09 -0.815226  \n",
       "...              ...  \n",
       "2018-12-24  0.202531  \n",
       "2018-12-26  0.520857  \n",
       "2018-12-27  0.423706  \n",
       "2018-12-28  0.165055  \n",
       "2018-12-31 -0.060541  \n",
       "\n",
       "[502 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stock data\n",
    "\n",
    "ticker = \"^DJI\"\n",
    "stockDf = P.read_csv(pathStocks / f'{ticker}.csv').set_index('Date')\n",
    "stockDf.index = stockDf.index.map(datetime.datetime.fromisoformat).map(lambda x:x.date())\n",
    "stockDf_train = stockDf[stockDf.index.map(lambda x:startTrain <= x and x < endTrain)]\n",
    "stockDf_test = stockDf[stockDf.index.map(lambda x:startTest <= x and x < endTest)]\n",
    "stockDf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2017, 3, 16),\n",
       "  array(['play resume after tea', 'lack could cost millions',\n",
       "         'to waive off farm loans in uttar pradesh', ...,\n",
       "         \"judge put donald trump's travel ban\", 'people have get notices',\n",
       "         'trumps budget would cut epa funding'], dtype='<U103')),\n",
       " (datetime.date(2018, 6, 1),\n",
       "  array(['ray mckinnon to be appoint as greenock morton manager',\n",
       "         'on twitter realdonaldtrump have a lot',\n",
       "         'donald trump must hold via usatoday', ...,\n",
       "         'cnbc - oil prices be tank as russia',\n",
       "         'archaeologists find his 2,000-year-old remains',\n",
       "         'with trump takeover gop'], dtype='<U118'))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_sample_transform = common.data.get_data_to_sample_transform(word2vec, embeddingProperties, stockDf['Y'], sc=sc)\n",
    "\n",
    "rddTrain = sc.pickleFile(str(pathTrainInstances), 32) \\\n",
    "    .cache()\n",
    "rddTrain.takeSample(False, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathModel = Path(f'models/nn-convatt-{ticker}')\n",
    "pathModel.mkdir(exist_ok=True, parents=True)\n",
    "nWorkers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Stage2Type2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 2048, 26, 12 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "td_Conv1 (TimeDistributed)      (None, 2048, 26, 64) 32832       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1A (LeakyReLU)              (None, 2048, 26, 64) 0           td_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "td_Pool1 (TimeDistributed)      (None, 2048, 13, 64) 0           Conv1A[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "td_Conv2 (TimeDistributed)      (None, 2048, 13, 64) 16448       td_Pool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2A (LeakyReLU)              (None, 2048, 13, 64) 0           td_Conv2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "td_Pool2 (TimeDistributed)      (None, 2048, 6, 64)  0           Conv2A[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "td_Conv3 (TimeDistributed)      (None, 2048, 6, 6)   1542        td_Pool2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3A (LeakyReLU)              (None, 2048, 6, 6)   0           td_Conv3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "td_Flatten (TimeDistributed)    (None, 2048, 36)     0           Conv3A[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "AttentionQueryDense (Dense)     (None, 2048, 36)     1332        td_Flatten[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "QueryPool (GlobalMaxPooling1D)  (None, 36)           0           AttentionQueryDense[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "QueryReshape (Reshape)          (None, 1, 36)        0           QueryPool[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Attention (Attention)           (None, 1, 36)        0           QueryReshape[0][0]               \n",
      "                                                                 td_Flatten[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten2 (Flatten)              (None, 36)           0           Attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 32)           1184        Flatten2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dense1A (LeakyReLU)             (None, 32)           0           Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "DenseO (Dense)                  (None, 1)            33          Dense1A[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 53,371\n",
      "Trainable params: 53,371\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def time_dist(l):\n",
    "    return KL.TimeDistributed(l, name='td_' + l.name)\n",
    "def create_model(name=\"Stage2Type2\"):\n",
    "    \n",
    "    def get_act(n):\n",
    "        return KL.LeakyReLU(0.01, name=n)\n",
    "    def get_kernel_reg():\n",
    "        return KR.l2(1e-4)\n",
    "    lIn = KL.Input((sampleProperties['sampleSize'], embeddingProperties['tweet_len'], embeddingProperties['embedding_size']), name=\"Input\")\n",
    "    layers = [\n",
    "        # \n",
    "        time_dist(KL.Conv1D(64, 4, 1, kernel_regularizer=get_kernel_reg(), padding='same', name='Conv1')),\n",
    "        get_act('Conv1A'),\n",
    "        time_dist(KL.MaxPooling1D(2, name='Pool1')),\n",
    "        time_dist(KL.Conv1D(64, 4, 1, kernel_regularizer=get_kernel_reg(), padding='same', name='Conv2')),\n",
    "        get_act('Conv2A'),\n",
    "        time_dist(KL.MaxPooling1D(2, name='Pool2')),\n",
    "        time_dist(KL.Conv1D(6, 4, 1, kernel_regularizer=get_kernel_reg(), padding='same', name='Conv3')),\n",
    "        get_act('Conv3A'),\n",
    "        time_dist(KL.Flatten(name=\"Flatten\")),\n",
    "    ]\n",
    "    out = lIn\n",
    "    for l in layers:\n",
    "        out = l(out)\n",
    "    \n",
    "    query_out = out\n",
    "    query_out = KL.Dense(36, activation='sigmoid', name='AttentionQueryDense')(query_out)\n",
    "    query_out = KL.GlobalMaxPooling1D(name=\"QueryPool\")(query_out)\n",
    "    query_out = KL.Reshape(target_shape=(1,36), name=\"QueryReshape\")(query_out)\n",
    "    out = KL.Attention(dropout=0.1, name=\"Attention\")([query_out, out])\n",
    "    \n",
    "    layers = [\n",
    "        KL.Flatten(name=\"Flatten2\"),\n",
    "        KL.Dense(32, kernel_regularizer=get_kernel_reg(), name=\"Dense1\"),\n",
    "        get_act('Dense1A'),\n",
    "        KL.Dense(1, kernel_regularizer=get_kernel_reg(), activation=None, name=\"DenseO\"),\n",
    "    ]\n",
    "    for l in layers:\n",
    "        out = l(out)\n",
    "        \n",
    "    return KM.Model(inputs=lIn, outputs=out, name=name)\n",
    "\n",
    "if nWorkers > 0:\n",
    "    model = create_model()\n",
    "else:\n",
    "    with tf_strategy.scope():\n",
    "        model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_accuracy(y_true, y_pred):\n",
    "    return KB.mean((y_true * y_pred) >= 0)\n",
    "model.compile(loss='mse', metrics=['mse', sign_accuracy], optimizer='adam')\n",
    "callback_checkpoint = KCb.ModelCheckpoint(str(pathModel / 'e{epoch:02d}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "WARNING:tensorflow:From /usr/local/lib64/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.6903 - mse: 0.6824 - sign_accuracy: 0.5540WARNING:tensorflow:From /usr/local/lib64/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib64/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e02/assets\n",
      "512/512 [==============================] - 2308s 5s/step - loss: 0.6903 - mse: 0.6824 - sign_accuracy: 0.5540\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.6592 - mse: 0.6543 - sign_accuracy: 0.5791INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e03/assets\n",
      "512/512 [==============================] - 2321s 5s/step - loss: 0.6592 - mse: 0.6543 - sign_accuracy: 0.5791\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.6288 - mse: 0.6205 - sign_accuracy: 0.6262INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e04/assets\n",
      "512/512 [==============================] - 2319s 5s/step - loss: 0.6288 - mse: 0.6205 - sign_accuracy: 0.6262\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.5537 - mse: 0.5419 - sign_accuracy: 0.6738INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e05/assets\n",
      "512/512 [==============================] - 2323s 5s/step - loss: 0.5537 - mse: 0.5419 - sign_accuracy: 0.6738\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.5503 - mse: 0.5360 - sign_accuracy: 0.6917INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e06/assets\n",
      "512/512 [==============================] - 2320s 5s/step - loss: 0.5503 - mse: 0.5360 - sign_accuracy: 0.6917\n",
      "Epoch 7/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4975 - mse: 0.4813 - sign_accuracy: 0.7006INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e07/assets\n",
      "512/512 [==============================] - 2330s 5s/step - loss: 0.4975 - mse: 0.4813 - sign_accuracy: 0.7006\n",
      "Epoch 8/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4698 - mse: 0.4520 - sign_accuracy: 0.7195INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e08/assets\n",
      "512/512 [==============================] - 2331s 5s/step - loss: 0.4698 - mse: 0.4520 - sign_accuracy: 0.7195\n",
      "Epoch 9/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4928 - mse: 0.4739 - sign_accuracy: 0.7125INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e09/assets\n",
      "512/512 [==============================] - 2325s 5s/step - loss: 0.4928 - mse: 0.4739 - sign_accuracy: 0.7125\n",
      "Epoch 10/10\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4940 - mse: 0.4731 - sign_accuracy: 0.7251INFO:tensorflow:Assets written to: models/nn-convatt-^DJI/e10/assets\n",
      "512/512 [==============================] - 2310s 5s/step - loss: 0.4940 - mse: 0.4731 - sign_accuracy: 0.7251\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "if nWorkers > 0:\n",
    "    sparkModel = ESm.SparkModel(model, frequency='epoch', mode='asynchronous')\n",
    "    sparkModel.master_optimizer = KO.Adam()\n",
    "    hist = sparkModel.fit(rddTrain.repartition(nWorkers), epochs=nEpochs, batch_size=32, verbose=1)\n",
    "    model.save(pathModel / 'e10')\n",
    "else:\n",
    "    batch_size = 16\n",
    "    repeat_batch = 4\n",
    "    def sample_generator():\n",
    "        while True:\n",
    "            x = rddTrain.takeSample(False, batch_size*repeat_batch)\n",
    "            x = [data_to_sample_transform(s) for s in x]\n",
    "            x, y = zip(*x)\n",
    "            x = N.array(x)\n",
    "            y = N.array(y)\n",
    "            for i in range(repeat_batch):\n",
    "                slic = slice(i*batch_size, (i+1)*batch_size)\n",
    "                yield x[slic], y[slic]\n",
    "    hist = model.fit(x=sample_generator(), initial_epoch=1, epochs=nEpochs,  steps_per_epoch=512, callbacks=[callback_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pathModel / 'hist.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'params': hist.params,\n",
    "        'history': hist.history,\n",
    "        'epoch': hist.epoch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
